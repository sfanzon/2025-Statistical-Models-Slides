---
title: "Statistical Models"
subtitle: "Lecture 5"
from: markdown+emoji
author: 
    - name: Dr. Silvio Fanzon
      id: sf
      email: S.Fanzon@hull.ac.uk
      url: https://www.silviofanzon.com
      affiliations: University of Hull
---



::: {.content-hidden}
$
{{< include macros.tex >}}
$
:::




# Lecture 5: <br>Hypothesis tests in R <br>Part 2 {background-color="#cc0164" visibility="uncounted"}

::: footer

<div color="#cc0164">  </div>

:::





## Lecture Overview {.smaller}

In Lecture 4:

- Looked at data before and after the 2008 crash
- In this case data for each month is directly comparable
- Can then construct the difference between the 2007 and 2009 values
- Analysis reduces from a two-sample to a one-sample problem

::: Question

How do we analyze two samples that cannot be paired?

:::





## Problem statement {.smaller}

**Goal:** compare mean and variance of 2 independent samples

- First sample:
    * Sample size $n$, sample mean $\overline{x}$, sample variance $s^2_X$

- Second sample:
    * Sample size $m$, sample mean $\overline{y}$, sample variance $s^2_Y$

- We may have $n \neq m$ 
    * Samples cannot be paired!

**Tests available:**

- Two-sample $t$-test to test for difference in means
- Two-sample $F$-test to test for difference in variances




## Why is this important? {.smaller}

- Hypothesis testing starts to get interesting with 2 or more samples

- t-test and F-test show the normal distribution family in action

- This is also the maths behind regression
    * Same methods apply to seemingly unrelated problems
    * Regression is a big subject in statistics




## Normal distribution family in action {.smaller}
### Two-sample t-test

- Want to compare the means of two independent samples
- At the same time population variances are unknown
- Therefore both variances are estimated with sample variances
- Test statistic is $t_k$-distributed with $k$ linked to the total number of observations




## Normal distribution family in action {.smaller}
### Two-sample F-test

- Want to compare the variance of two independent samples
- This can be done by studying the ratio of the sample variances
$$
s^2_X/s^2_Y
$$

- We have already shown that
$$
\frac{(n - 1) S^2_X}{\sigma^2_X} \sim \chi^2_{n - 1} \qquad 
\frac{(m - 1) S^2_Y}{\sigma^2_Y} \sim \chi^2_{m - 1}
$$



## Normal distribution family in action {.smaller}
### Two-sample F-test


- Hence we can study statistic
$$
F = \frac{S^2_X / \sigma_X^2}{S^2_Y / \sigma_Y^2}
$$

- We will see that $F$ has F-distribution






## Outline of Lecture 5


1. The F-distribution




# Part 3: <br>The F-distribution {background-color="#cc0164" visibility="uncounted"}

::: footer

<div color="#cc0164">  </div>

:::



## Overview {.smaller}
### Chi-squared distribution

**Recall**: The chi-squared distribution with $p$ degrees of freedom is
$$
\chi_p^2 = Z_1^2 + \ldots + Z_p^2
$$
where $Z_1, \ldots, Z_n$ are iid $N(0, 1)$




## Overview {.smaller}
### Chi-squared distribution

Chi-squared distribution was used to:

- Describe distribution of sample variance $S^2$:
$$
\frac{(n-1)S^2}{\sigma^2} \sim \chi_{n-1}^2
$$

- Define t-distribution:
$$
t_p \sim \frac{U}{\sqrt{V/p}}
$$
where $U \sim N(0,1)$ and $V \sim \chi_p^2$ independent





## The F-distribution {.smaller}

F-distribution is:

- Defined in terms of ratio of $\chi_p^2$
- Describes **variance estimators** for independent samples


::: Definition

The r.v. $F$ has F-distribution with $p$ and $q$ degrees of freedom
if the pdf is
$$
f_F(x) = \frac{ \Gamma \left(\frac{p+q}{2} \right) }{ \Gamma \left( \frac{p}{2} \right) \Gamma \left( \frac{q}{2} \right) } 
\left( \frac{p}{q} \right)^{p/2} \, 
\frac{ x^{ (p/2) - 1 } }{ [ 1 + (p/q) x ]^{(p+q)/2} } \,, \quad x > 0
$$


:::


**Notation**:  F-distribution with $p$ and $q$ degrees of freedom is denoted by $F_{p,q}$






## Characterization of F-distribution {.smaller}

The F-distribution is obtained as ratio of 2 independent chi-squared distributions

::: Theorem

Suppose that $U \sim \chi_p^2$ and $V \sim \chi_q^2$ are independent. Then
$$
X := \frac{U/p}{V/q} \sim F_{p,q}
$$

:::



## Idea of Proof {.smaller}

- This is similar to the proof (seen in Homework 2) that 
$$
\frac{U}{\sqrt{V/p}} \sim t_p
$$
where $U \sim N(0,1)$ and $V \sim \chi_p^2$ are independent 

- In our case we need to prove
$$
X := \frac{U/p}{V/q} \sim F_{p,q}
$$
where $U \sim \chi_p^2$ and $V \sim \chi_q^2$ are independent




## Idea of Proof {.smaller}

- $U \sim \chi_{p}^2$ and $V \sim \chi_q^2$ are independent. Therefore
\begin{align*}
f_{U,V} (u,v) & = f_U(u) f_V(v) \\
              & = 
\frac{ 1 }{ \Gamma \left( \frac{p}{2} \right) \Gamma \left( \frac{q}{2} \right) 2^{(p+q)/2} }  u^{\frac{p}{2} - 1}
v^{\frac{q}{2} - 1} e^{-(u+v)/2}
\end{align*}


- Consider the change of variables 
$$
x(u,v) := \frac{u/p}{v/q} \,, \quad y(u,v) := u + v
$$




## Idea of Proof {.smaller}

- This way we have
$$
X = \frac{U/p}{V/q}  \,, \qquad Y = U + V
$$


- To conclude the proof, we need to compute the pdf of $X$, that is $f_X$

- This can be computed as the $X$ marginal of $f_{X,Y}$
$$
f_{X}(x) = \int_{0}^\infty f_{X,Y}(x,y) \, dy
$$



## Idea of Proof {.smaller}

- The joint pdf $f_{X,Y}$ can be computed by inverting the change of variables
$$
x(u,v) := \frac{u/p}{v/q} \,, \quad y(u,v) := u + v
$$
and using the formula
$$
f_{X,Y}(x,y) = f_{U,V}(u(x,y),v(x,y)) \, |\det J|
$$
where $J$ is the Jacobian of the inverse transformation 
$$
(x,y) \mapsto (u(x,y),v(x,y))
$$



## Idea of Proof {.smaller}

- Since $f_{U,V}$ is known, then also $f_{X,Y}$ is known

- Moreover the integral
$$
f_{X}(x) = \int_{0}^\infty f_{X,Y}(x,y) \, dy
$$
can be explicitly computed, yielding the thesis
$$
f_{X}(x) = \frac{ \Gamma \left(\frac{p+q}{2} \right) }{ \Gamma \left( \frac{p}{2} \right) \Gamma \left( \frac{q}{2} \right) } 
\left( \frac{p}{q} \right)^{p/2} \, 
\frac{ x^{ (p/2) - 1 } }{ [ 1 + (p/q) x ]^{(p+q)/2} }
$$




## Properties of F-distribution {.smaller}

::: Theorem

1. Suppose $X \sim F_{p,q}$ with $q>2$. Then 
$$
\Expect[X] = \frac{q}{q-2}
$$

2. If $X \sim F_{p,q}$ then $1/X \sim F_{q,p}$

3. If $X \sim t_q$ then $X^2 \sim F_{1,q}$

:::




## Properties of F-distribution {.smaller}
### Proof of Theorem

1. Requires a bit of work. It will be left as Homework assignment

2. By the Theorem in Slide 44, we have
$$
X \sim F_{p,q} \quad \implies \quad X = \frac{U/p}{V/q}
$$
with $U \sim \chi_p^2$ and $V \sim \chi_q^2$ independent. Therefore
$$
\frac{1}{X} = \frac{V/q}{U/p} \sim  \frac{\chi^2_q/q}{\chi^2_p/p} \sim F_{q,p}
$$



## Properties of F-distribution {.smaller}
### Proof of Theorem

3. Suppose $X \sim t_q$. The Theorem in Slide 118 of Lecture 2, guarantees that
$$
X = \frac{U}{\sqrt{V/q}}
$$
where $U \sim N(0,1)$ and $V \sim \chi_q^2$ are independent. Therefore
$$
X^2 = \frac{U^2}{V/q}
$$



## Properties of F-distribution {.smaller}
### Proof of Theorem

- Since $U \sim N(0,1)$, by definition $U^2 \sim \chi_1^2$. 
- Moreover $U^2$ and $V$ are independet, since $U$ and $V$ are independent
- Finally, the Theorem in Slide 44 implies
$$
X^2 = \frac{U^2}{V/q} \sim \frac{\chi_1^2/1}{\chi_q^2/q} \sim F_{1,q} 
$$






## References